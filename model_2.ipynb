{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting sklearn\n  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\nRequirement already satisfied, skipping upgrade: scikit-learn in /Users/amosfung/miniconda3/envs/PythonData/lib/python3.6/site-packages (from sklearn) (0.21.3)\nRequirement already satisfied, skipping upgrade: numpy>=1.11.0 in /Users/amosfung/miniconda3/envs/PythonData/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.17.3)\nRequirement already satisfied, skipping upgrade: scipy>=0.17.0 in /Users/amosfung/miniconda3/envs/PythonData/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.3.1)\nRequirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/amosfung/miniconda3/envs/PythonData/lib/python3.6/site-packages (from scikit-learn->sklearn) (0.14.0)\nBuilding wheels for collected packages: sklearn\n  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=2befafc76e0523d0391c1397f1ef5facbd9adf8d5a805bd5eada80e188599fed\n  Stored in directory: /Users/amosfung/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\nSuccessfully built sklearn\nInstalling collected packages: sklearn\nSuccessfully installed sklearn-0.0\n"
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: joblib in /Users/amosfung/miniconda3/envs/PythonData/lib/python3.6/site-packages (0.14.0)\n"
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n0       CONFIRMED              0              0              0              0   \n1  FALSE POSITIVE              0              1              0              0   \n2  FALSE POSITIVE              0              1              0              0   \n3       CONFIRMED              0              0              0              0   \n4       CONFIRMED              0              0              0              0   \n\n   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n\n   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n0          0.003520  ...             -81      4.467           0.064   \n1          0.000581  ...            -176      4.544           0.044   \n2          0.000115  ...            -174      4.564           0.053   \n3          0.001130  ...            -211      4.438           0.070   \n4          0.001900  ...            -232      4.486           0.054   \n\n   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n0          -0.096     0.927          0.105         -0.061  291.93423   \n1          -0.176     0.868          0.233         -0.078  297.00482   \n2          -0.168     0.791          0.201         -0.067  285.53461   \n3          -0.210     1.046          0.334         -0.133  288.75488   \n4          -0.229     0.972          0.315         -0.105  296.28613   \n\n         dec  koi_kepmag  \n0  48.141651      15.347  \n1  48.134129      15.436  \n2  48.285210      15.597  \n3  48.226200      15.509  \n4  48.224670      15.714  \n\n[5 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>koi_disposition</th>\n      <th>koi_fpflag_nt</th>\n      <th>koi_fpflag_ss</th>\n      <th>koi_fpflag_co</th>\n      <th>koi_fpflag_ec</th>\n      <th>koi_period</th>\n      <th>koi_period_err1</th>\n      <th>koi_period_err2</th>\n      <th>koi_time0bk</th>\n      <th>koi_time0bk_err1</th>\n      <th>...</th>\n      <th>koi_steff_err2</th>\n      <th>koi_slogg</th>\n      <th>koi_slogg_err1</th>\n      <th>koi_slogg_err2</th>\n      <th>koi_srad</th>\n      <th>koi_srad_err1</th>\n      <th>koi_srad_err2</th>\n      <th>ra</th>\n      <th>dec</th>\n      <th>koi_kepmag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CONFIRMED</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>54.418383</td>\n      <td>2.479000e-04</td>\n      <td>-2.479000e-04</td>\n      <td>162.513840</td>\n      <td>0.003520</td>\n      <td>...</td>\n      <td>-81</td>\n      <td>4.467</td>\n      <td>0.064</td>\n      <td>-0.096</td>\n      <td>0.927</td>\n      <td>0.105</td>\n      <td>-0.061</td>\n      <td>291.93423</td>\n      <td>48.141651</td>\n      <td>15.347</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19.899140</td>\n      <td>1.490000e-05</td>\n      <td>-1.490000e-05</td>\n      <td>175.850252</td>\n      <td>0.000581</td>\n      <td>...</td>\n      <td>-176</td>\n      <td>4.544</td>\n      <td>0.044</td>\n      <td>-0.176</td>\n      <td>0.868</td>\n      <td>0.233</td>\n      <td>-0.078</td>\n      <td>297.00482</td>\n      <td>48.134129</td>\n      <td>15.436</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.736952</td>\n      <td>2.630000e-07</td>\n      <td>-2.630000e-07</td>\n      <td>170.307565</td>\n      <td>0.000115</td>\n      <td>...</td>\n      <td>-174</td>\n      <td>4.564</td>\n      <td>0.053</td>\n      <td>-0.168</td>\n      <td>0.791</td>\n      <td>0.201</td>\n      <td>-0.067</td>\n      <td>285.53461</td>\n      <td>48.285210</td>\n      <td>15.597</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CONFIRMED</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.525592</td>\n      <td>3.760000e-06</td>\n      <td>-3.760000e-06</td>\n      <td>171.595550</td>\n      <td>0.001130</td>\n      <td>...</td>\n      <td>-211</td>\n      <td>4.438</td>\n      <td>0.070</td>\n      <td>-0.210</td>\n      <td>1.046</td>\n      <td>0.334</td>\n      <td>-0.133</td>\n      <td>288.75488</td>\n      <td>48.226200</td>\n      <td>15.509</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CONFIRMED</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.134435</td>\n      <td>1.050000e-05</td>\n      <td>-1.050000e-05</td>\n      <td>172.979370</td>\n      <td>0.001900</td>\n      <td>...</td>\n      <td>-232</td>\n      <td>4.486</td>\n      <td>0.054</td>\n      <td>-0.229</td>\n      <td>0.972</td>\n      <td>0.315</td>\n      <td>-0.105</td>\n      <td>296.28613</td>\n      <td>48.224670</td>\n      <td>15.714</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = df[['koi_period', 'koi_prad', 'koi_fpflag_nt', 'koi_steff', 'koi_slogg', 'koi_srad']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, df['koi_disposition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data for dnn\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df['koi_disposition'])\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "y_train_categorical = to_categorical(y_train_encoded)\n",
    "y_test_categorical = to_categorical(y_train_encoded)\n",
    "\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5243, 3)"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "y_train_categorical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n - 0s - loss: 0.9434 - acc: 0.5085\nEpoch 2/50\n - 0s - loss: 0.8873 - acc: 0.5400\nEpoch 3/50\n - 0s - loss: 0.8806 - acc: 0.5487\nEpoch 4/50\n - 0s - loss: 0.8776 - acc: 0.5508\nEpoch 5/50\n - 0s - loss: 0.8707 - acc: 0.5556\nEpoch 6/50\n - 0s - loss: 0.8699 - acc: 0.5566\nEpoch 7/50\n - 0s - loss: 0.8686 - acc: 0.5607\nEpoch 8/50\n - 0s - loss: 0.8642 - acc: 0.5644\nEpoch 9/50\n - 0s - loss: 0.8642 - acc: 0.5592\nEpoch 10/50\n - 0s - loss: 0.8625 - acc: 0.5609\nEpoch 11/50\n - 0s - loss: 0.8598 - acc: 0.5613\nEpoch 12/50\n - 0s - loss: 0.8551 - acc: 0.5678\nEpoch 13/50\n - 0s - loss: 0.8550 - acc: 0.5697\nEpoch 14/50\n - 0s - loss: 0.8505 - acc: 0.5716\nEpoch 15/50\n - 0s - loss: 0.8534 - acc: 0.5678\nEpoch 16/50\n - 0s - loss: 0.8476 - acc: 0.5773\nEpoch 17/50\n - 0s - loss: 0.8478 - acc: 0.5787\nEpoch 18/50\n - 0s - loss: 0.8453 - acc: 0.5762\nEpoch 19/50\n - 0s - loss: 0.8435 - acc: 0.5848\nEpoch 20/50\n - 0s - loss: 0.8392 - acc: 0.5834\nEpoch 21/50\n - 0s - loss: 0.8387 - acc: 0.5857\nEpoch 22/50\n - 0s - loss: 0.8382 - acc: 0.5897\nEpoch 23/50\n - 0s - loss: 0.8326 - acc: 0.5926\nEpoch 24/50\n - 0s - loss: 0.8328 - acc: 0.5930\nEpoch 25/50\n - 0s - loss: 0.8299 - acc: 0.5951\nEpoch 26/50\n - 0s - loss: 0.8274 - acc: 0.5924\nEpoch 27/50\n - 0s - loss: 0.8275 - acc: 0.5976\nEpoch 28/50\n - 0s - loss: 0.8337 - acc: 0.5901\nEpoch 29/50\n - 0s - loss: 0.8232 - acc: 0.6000\nEpoch 30/50\n - 0s - loss: 0.8270 - acc: 0.5976\nEpoch 31/50\n - 0s - loss: 0.8221 - acc: 0.5949\nEpoch 32/50\n - 0s - loss: 0.8264 - acc: 0.5951\nEpoch 33/50\n - 0s - loss: 0.8222 - acc: 0.6008\nEpoch 34/50\n - 0s - loss: 0.8188 - acc: 0.6029\nEpoch 35/50\n - 0s - loss: 0.8166 - acc: 0.6071\nEpoch 36/50\n - 0s - loss: 0.8166 - acc: 0.6048\nEpoch 37/50\n - 0s - loss: 0.8140 - acc: 0.6040\nEpoch 38/50\n - 0s - loss: 0.8166 - acc: 0.6012\nEpoch 39/50\n - 0s - loss: 0.8085 - acc: 0.6050\nEpoch 40/50\n - 0s - loss: 0.8122 - acc: 0.6008\nEpoch 41/50\n - 0s - loss: 0.8113 - acc: 0.6027\nEpoch 42/50\n - 0s - loss: 0.8101 - acc: 0.6067\nEpoch 43/50\n - 0s - loss: 0.8055 - acc: 0.6061\nEpoch 44/50\n - 0s - loss: 0.8079 - acc: 0.6046\nEpoch 45/50\n - 0s - loss: 0.8036 - acc: 0.6132\nEpoch 46/50\n - 0s - loss: 0.8002 - acc: 0.6096\nEpoch 47/50\n - 0s - loss: 0.7990 - acc: 0.6124\nEpoch 48/50\n - 0s - loss: 0.7978 - acc: 0.6113\nEpoch 49/50\n - 0s - loss: 0.8043 - acc: 0.6073\nEpoch 50/50\n - 0s - loss: 0.8002 - acc: 0.6155\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1a35092940>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# function to create deep learning model with sklearn wrapper\n",
    "# def make_model():\n",
    "#     deep_neural_model = Sequential()\n",
    "#     deep_neural_model.add(Dense(100, activation = 'relu', input_dim = 6))\n",
    "#     deep_neural_model.add(Dense(100, activation = 'relu'))\n",
    "#     deep_neural_model.add(Dense(3, activation = 'softmax'))\n",
    "#     deep_neural_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return deep_neural_model\n",
    "\n",
    "# deep_neural_model = KerasClassifier(build_fn=make_model, epochs = 100, batch_size =10, verbose=2)\n",
    "\n",
    "deep_neural_model = Sequential()\n",
    "deep_neural_model.add(Dense(100, activation = 'relu', input_dim = 6))\n",
    "deep_neural_model.add(Dense(100, activation = 'relu'))\n",
    "deep_neural_model.add(Dense(3, activation = 'softmax'))\n",
    "deep_neural_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "deep_neural_model.fit(X_train_scaled, y_train_categorical, epochs=50, shuffle = True, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5243/5243 [==============================] - 0s 38us/sample - loss: 0.7794 - acc: 0.6273\n1748/1748 [==============================] - 0s 23us/sample - loss: 0.7963 - acc: 0.6270\nTraining Data Loss: 0.7794291235530693, Training Data Accuracy: 0.6273126006126404\nTesting Data Loss: 0.7963326492898797, Testing Data Accuracy: 0.6270022988319397\n"
    }
   ],
   "source": [
    "model_train_loss, model_train_accuracy = deep_neural_model.evaluate(X_train_scaled, y_train_categorical)\n",
    "model_test_loss, model_test_accuracy = deep_neural_model.evaluate(X_test_scaled, y_test_categorical)\n",
    "\n",
    "print(f\"Training Data Loss: {model_train_loss}, Training Data Accuracy: {model_train_accuracy}\")\n",
    "print(f\"Testing Data Loss: {model_test_loss}, Testing Data Accuracy: {model_test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.9min\n[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  4.9min finished\nEpoch 1/100\n - 1s - loss: 0.9270 - acc: 0.5199\nEpoch 2/100\n - 0s - loss: 0.8848 - acc: 0.5442\nEpoch 3/100\n - 0s - loss: 0.8775 - acc: 0.5525\nEpoch 4/100\n - 0s - loss: 0.8741 - acc: 0.5598\nEpoch 5/100\n - 0s - loss: 0.8693 - acc: 0.5573\nEpoch 6/100\n - 0s - loss: 0.8648 - acc: 0.5646\nEpoch 7/100\n - 0s - loss: 0.8661 - acc: 0.5598\nEpoch 8/100\n - 0s - loss: 0.8594 - acc: 0.5621\nEpoch 9/100\n - 0s - loss: 0.8578 - acc: 0.5716\nEpoch 10/100\n - 0s - loss: 0.8583 - acc: 0.5712\nEpoch 11/100\n - 0s - loss: 0.8550 - acc: 0.5728\nEpoch 12/100\n - 0s - loss: 0.8495 - acc: 0.5739\nEpoch 13/100\n - 0s - loss: 0.8466 - acc: 0.5739\nEpoch 14/100\n - 0s - loss: 0.8450 - acc: 0.5777\nEpoch 15/100\n - 0s - loss: 0.8462 - acc: 0.5819\nEpoch 16/100\n - 0s - loss: 0.8422 - acc: 0.5878\nEpoch 17/100\n - 0s - loss: 0.8394 - acc: 0.5817\nEpoch 18/100\n - 0s - loss: 0.8375 - acc: 0.5873\nEpoch 19/100\n - 0s - loss: 0.8337 - acc: 0.5951\nEpoch 20/100\n - 0s - loss: 0.8312 - acc: 0.5941\nEpoch 21/100\n - 0s - loss: 0.8304 - acc: 0.5905\nEpoch 22/100\n - 0s - loss: 0.8257 - acc: 0.5920\nEpoch 23/100\n - 0s - loss: 0.8225 - acc: 0.5985\nEpoch 24/100\n - 0s - loss: 0.8197 - acc: 0.6063\nEpoch 25/100\n - 0s - loss: 0.8232 - acc: 0.6021\nEpoch 26/100\n - 0s - loss: 0.8194 - acc: 0.6019\nEpoch 27/100\n - 0s - loss: 0.8154 - acc: 0.6025\nEpoch 28/100\n - 0s - loss: 0.8199 - acc: 0.5983\nEpoch 29/100\n - 0s - loss: 0.8132 - acc: 0.6056\nEpoch 30/100\n - 0s - loss: 0.8133 - acc: 0.6033\nEpoch 31/100\n - 0s - loss: 0.8148 - acc: 0.6035\nEpoch 32/100\n - 0s - loss: 0.8106 - acc: 0.6086\nEpoch 33/100\n - 0s - loss: 0.8168 - acc: 0.6035\nEpoch 34/100\n - 0s - loss: 0.8066 - acc: 0.6075\nEpoch 35/100\n - 0s - loss: 0.8055 - acc: 0.6069\nEpoch 36/100\n - 0s - loss: 0.8039 - acc: 0.6082\nEpoch 37/100\n - 0s - loss: 0.8026 - acc: 0.6044\nEpoch 38/100\n - 0s - loss: 0.8015 - acc: 0.6101\nEpoch 39/100\n - 0s - loss: 0.7971 - acc: 0.6157\nEpoch 40/100\n - 0s - loss: 0.8166 - acc: 0.5976\nEpoch 41/100\n - 0s - loss: 0.8034 - acc: 0.6100\nEpoch 42/100\n - 0s - loss: 0.8036 - acc: 0.6101\nEpoch 43/100\n - 0s - loss: 0.7944 - acc: 0.6155\nEpoch 44/100\n - 0s - loss: 0.7961 - acc: 0.6185\nEpoch 45/100\n - 0s - loss: 0.8003 - acc: 0.6159\nEpoch 46/100\n - 0s - loss: 0.7925 - acc: 0.6201\nEpoch 47/100\n - 0s - loss: 0.7932 - acc: 0.6157\nEpoch 48/100\n - 0s - loss: 0.7901 - acc: 0.6164\nEpoch 49/100\n - 0s - loss: 0.7874 - acc: 0.6210\nEpoch 50/100\n - 0s - loss: 0.7890 - acc: 0.6204\nEpoch 51/100\n - 0s - loss: 0.7829 - acc: 0.6231\nEpoch 52/100\n - 0s - loss: 0.7829 - acc: 0.6260\nEpoch 53/100\n - 0s - loss: 0.7786 - acc: 0.6277\nEpoch 54/100\n - 0s - loss: 0.7814 - acc: 0.6275\nEpoch 55/100\n - 0s - loss: 0.7791 - acc: 0.6357\nEpoch 56/100\n - 0s - loss: 0.7823 - acc: 0.6275\nEpoch 57/100\n - 0s - loss: 0.7789 - acc: 0.6292\nEpoch 58/100\n - 0s - loss: 0.7791 - acc: 0.6306\nEpoch 59/100\n - 0s - loss: 0.7712 - acc: 0.6334\nEpoch 60/100\n - 0s - loss: 0.7765 - acc: 0.6292\nEpoch 61/100\n - 0s - loss: 0.7729 - acc: 0.6372\nEpoch 62/100\n - 0s - loss: 0.7754 - acc: 0.6302\nEpoch 63/100\n - 0s - loss: 0.7735 - acc: 0.6332\nEpoch 64/100\n - 0s - loss: 0.7651 - acc: 0.6386\nEpoch 65/100\n - 0s - loss: 0.7647 - acc: 0.6395\nEpoch 66/100\n - 0s - loss: 0.7643 - acc: 0.6361\nEpoch 67/100\n - 0s - loss: 0.7689 - acc: 0.6351\nEpoch 68/100\n - 0s - loss: 0.7689 - acc: 0.6332\nEpoch 69/100\n - 0s - loss: 0.7701 - acc: 0.6338\nEpoch 70/100\n - 0s - loss: 0.7631 - acc: 0.6357\nEpoch 71/100\n - 0s - loss: 0.7597 - acc: 0.6368\nEpoch 72/100\n - 0s - loss: 0.7571 - acc: 0.6462\nEpoch 73/100\n - 0s - loss: 0.7617 - acc: 0.6374\nEpoch 74/100\n - 0s - loss: 0.7627 - acc: 0.6378\nEpoch 75/100\n - 0s - loss: 0.7610 - acc: 0.6397\nEpoch 76/100\n - 0s - loss: 0.7525 - acc: 0.6451\nEpoch 77/100\n - 0s - loss: 0.7575 - acc: 0.6435\nEpoch 78/100\n - 0s - loss: 0.7541 - acc: 0.6458\nEpoch 79/100\n - 0s - loss: 0.7512 - acc: 0.6458\nEpoch 80/100\n - 0s - loss: 0.7507 - acc: 0.6464\nEpoch 81/100\n - 0s - loss: 0.7463 - acc: 0.6555\nEpoch 82/100\n - 0s - loss: 0.7497 - acc: 0.6462\nEpoch 83/100\n - 0s - loss: 0.7425 - acc: 0.6542\nEpoch 84/100\n - 0s - loss: 0.7450 - acc: 0.6502\nEpoch 85/100\n - 0s - loss: 0.7419 - acc: 0.6544\nEpoch 86/100\n - 0s - loss: 0.7423 - acc: 0.6517\nEpoch 87/100\n - 0s - loss: 0.7396 - acc: 0.6555\nEpoch 88/100\n - 0s - loss: 0.7372 - acc: 0.6571\nEpoch 89/100\n - 0s - loss: 0.7355 - acc: 0.6553\nEpoch 90/100\n - 0s - loss: 0.7318 - acc: 0.6594\nEpoch 91/100\n - 0s - loss: 0.7290 - acc: 0.6630\nEpoch 92/100\n - 0s - loss: 0.7285 - acc: 0.6584\nEpoch 93/100\n - 0s - loss: 0.7262 - acc: 0.6651\nEpoch 94/100\n - 0s - loss: 0.7376 - acc: 0.6525\nEpoch 95/100\n - 0s - loss: 0.7268 - acc: 0.6653\nEpoch 96/100\n - 0s - loss: 0.7268 - acc: 0.6634\nEpoch 97/100\n - 0s - loss: 0.7208 - acc: 0.6691\nEpoch 98/100\n - 0s - loss: 0.7256 - acc: 0.6664\nEpoch 99/100\n - 0s - loss: 0.7227 - acc: 0.6683\nEpoch 100/100\n - 0s - loss: 0.7176 - acc: 0.6622\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=3, error_score='raise-deprecating',\n             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x1a335e41d0>,\n             iid='warn', n_jobs=-1,\n             param_grid={'batch_size': [10, 20, 30, 40, 50, 100],\n                         'epochs': [10, 50, 100]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='accuracy', verbose=2)"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras import optimizers\n",
    "params = {\n",
    "    'batch_size': [10, 20, 30, 40, 50, 100],\n",
    "    'epochs': [10, 50, 100]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=deep_neural_model, param_grid=params, scoring= 'accuracy',verbose = 2, n_jobs=-1, cv=3)\n",
    "grid.fit(X_train_scaled, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'batch_size': 20, 'epochs': 100}\n0.6469578485599847\n"
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "\n",
    "filename = 'exoplanet_dnn_model.h5'\n",
    "deep_neural_model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python36764bitpythondatacondac93f1d0824da4ea88fdc3c2e1b2950d1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}