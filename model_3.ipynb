{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting sklearn\n  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\nRequirement already satisfied, skipping upgrade: scikit-learn in /Users/amosfung/miniconda3/envs/PythonData/lib/python3.6/site-packages (from sklearn) (0.21.3)\nRequirement already satisfied, skipping upgrade: numpy>=1.11.0 in /Users/amosfung/miniconda3/envs/PythonData/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.17.3)\nRequirement already satisfied, skipping upgrade: scipy>=0.17.0 in /Users/amosfung/miniconda3/envs/PythonData/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.3.1)\nRequirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/amosfung/miniconda3/envs/PythonData/lib/python3.6/site-packages (from scikit-learn->sklearn) (0.14.0)\nBuilding wheels for collected packages: sklearn\n  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=2befafc76e0523d0391c1397f1ef5facbd9adf8d5a805bd5eada80e188599fed\n  Stored in directory: /Users/amosfung/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\nSuccessfully built sklearn\nInstalling collected packages: sklearn\nSuccessfully installed sklearn-0.0\n"
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: joblib in /Users/amosfung/miniconda3/envs/PythonData/lib/python3.6/site-packages (0.14.0)\n"
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n0          CONFIRMED              0              0              0   \n1     FALSE POSITIVE              0              1              0   \n2     FALSE POSITIVE              0              1              0   \n3          CONFIRMED              0              0              0   \n4          CONFIRMED              0              0              0   \n...              ...            ...            ...            ...   \n6983  FALSE POSITIVE              0              1              0   \n6986  FALSE POSITIVE              0              0              0   \n6987  FALSE POSITIVE              0              1              1   \n6989  FALSE POSITIVE              0              0              1   \n6990  FALSE POSITIVE              0              0              1   \n\n      koi_fpflag_ec  koi_period  koi_period_err1  koi_period_err2  \\\n0                 0   54.418383     2.479000e-04    -2.479000e-04   \n1                 0   19.899140     1.490000e-05    -1.490000e-05   \n2                 0    1.736952     2.630000e-07    -2.630000e-07   \n3                 0    2.525592     3.760000e-06    -3.760000e-06   \n4                 0    4.134435     1.050000e-05    -1.050000e-05   \n...             ...         ...              ...              ...   \n6983              0   21.513523     2.714000e-04    -2.714000e-04   \n6986              1    8.589871     1.846000e-04    -1.846000e-04   \n6987              0    0.527699     1.160000e-07    -1.160000e-07   \n6989              0    0.681402     2.430000e-06    -2.430000e-06   \n6990              1    4.856035     6.360000e-05    -6.360000e-05   \n\n      koi_time0bk  koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  \\\n0      162.513840          0.003520  ...             -81      4.467   \n1      175.850252          0.000581  ...            -176      4.544   \n2      170.307565          0.000115  ...            -174      4.564   \n3      171.595550          0.001130  ...            -211      4.438   \n4      172.979370          0.001900  ...            -232      4.486   \n...           ...               ...  ...             ...        ...   \n6983   132.335600          0.012200  ...            -141      3.508   \n6986   132.016100          0.015700  ...            -152      4.296   \n6987   131.705093          0.000170  ...            -166      4.529   \n6989   132.181750          0.002850  ...            -236      4.447   \n6990   135.993300          0.010800  ...            -225      4.385   \n\n      koi_slogg_err1  koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2  \\\n0              0.064          -0.096     0.927          0.105         -0.061   \n1              0.044          -0.176     0.868          0.233         -0.078   \n2              0.053          -0.168     0.791          0.201         -0.067   \n3              0.070          -0.210     1.046          0.334         -0.133   \n4              0.054          -0.229     0.972          0.315         -0.105   \n...              ...             ...       ...            ...            ...   \n6983           0.187          -0.153     3.318          0.665         -0.813   \n6986           0.231          -0.189     1.088          0.313         -0.228   \n6987           0.035          -0.196     0.903          0.237         -0.079   \n6989           0.056          -0.224     1.041          0.341         -0.114   \n6990           0.054          -0.216     1.193          0.410         -0.137   \n\n             ra        dec  koi_kepmag  \n0     291.93423  48.141651      15.347  \n1     297.00482  48.134129      15.436  \n2     285.53461  48.285210      15.597  \n3     288.75488  48.226200      15.509  \n4     296.28613  48.224670      15.714  \n...         ...        ...         ...  \n6983  287.46786  37.966640      10.630  \n6986  298.74921  46.973351      14.478  \n6987  297.18875  47.093819      14.082  \n6989  294.16489  47.176281      15.385  \n6990  297.00977  47.121021      14.826  \n\n[5304 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>koi_disposition</th>\n      <th>koi_fpflag_nt</th>\n      <th>koi_fpflag_ss</th>\n      <th>koi_fpflag_co</th>\n      <th>koi_fpflag_ec</th>\n      <th>koi_period</th>\n      <th>koi_period_err1</th>\n      <th>koi_period_err2</th>\n      <th>koi_time0bk</th>\n      <th>koi_time0bk_err1</th>\n      <th>...</th>\n      <th>koi_steff_err2</th>\n      <th>koi_slogg</th>\n      <th>koi_slogg_err1</th>\n      <th>koi_slogg_err2</th>\n      <th>koi_srad</th>\n      <th>koi_srad_err1</th>\n      <th>koi_srad_err2</th>\n      <th>ra</th>\n      <th>dec</th>\n      <th>koi_kepmag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CONFIRMED</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>54.418383</td>\n      <td>2.479000e-04</td>\n      <td>-2.479000e-04</td>\n      <td>162.513840</td>\n      <td>0.003520</td>\n      <td>...</td>\n      <td>-81</td>\n      <td>4.467</td>\n      <td>0.064</td>\n      <td>-0.096</td>\n      <td>0.927</td>\n      <td>0.105</td>\n      <td>-0.061</td>\n      <td>291.93423</td>\n      <td>48.141651</td>\n      <td>15.347</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19.899140</td>\n      <td>1.490000e-05</td>\n      <td>-1.490000e-05</td>\n      <td>175.850252</td>\n      <td>0.000581</td>\n      <td>...</td>\n      <td>-176</td>\n      <td>4.544</td>\n      <td>0.044</td>\n      <td>-0.176</td>\n      <td>0.868</td>\n      <td>0.233</td>\n      <td>-0.078</td>\n      <td>297.00482</td>\n      <td>48.134129</td>\n      <td>15.436</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.736952</td>\n      <td>2.630000e-07</td>\n      <td>-2.630000e-07</td>\n      <td>170.307565</td>\n      <td>0.000115</td>\n      <td>...</td>\n      <td>-174</td>\n      <td>4.564</td>\n      <td>0.053</td>\n      <td>-0.168</td>\n      <td>0.791</td>\n      <td>0.201</td>\n      <td>-0.067</td>\n      <td>285.53461</td>\n      <td>48.285210</td>\n      <td>15.597</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CONFIRMED</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.525592</td>\n      <td>3.760000e-06</td>\n      <td>-3.760000e-06</td>\n      <td>171.595550</td>\n      <td>0.001130</td>\n      <td>...</td>\n      <td>-211</td>\n      <td>4.438</td>\n      <td>0.070</td>\n      <td>-0.210</td>\n      <td>1.046</td>\n      <td>0.334</td>\n      <td>-0.133</td>\n      <td>288.75488</td>\n      <td>48.226200</td>\n      <td>15.509</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CONFIRMED</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.134435</td>\n      <td>1.050000e-05</td>\n      <td>-1.050000e-05</td>\n      <td>172.979370</td>\n      <td>0.001900</td>\n      <td>...</td>\n      <td>-232</td>\n      <td>4.486</td>\n      <td>0.054</td>\n      <td>-0.229</td>\n      <td>0.972</td>\n      <td>0.315</td>\n      <td>-0.105</td>\n      <td>296.28613</td>\n      <td>48.224670</td>\n      <td>15.714</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6983</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21.513523</td>\n      <td>2.714000e-04</td>\n      <td>-2.714000e-04</td>\n      <td>132.335600</td>\n      <td>0.012200</td>\n      <td>...</td>\n      <td>-141</td>\n      <td>3.508</td>\n      <td>0.187</td>\n      <td>-0.153</td>\n      <td>3.318</td>\n      <td>0.665</td>\n      <td>-0.813</td>\n      <td>287.46786</td>\n      <td>37.966640</td>\n      <td>10.630</td>\n    </tr>\n    <tr>\n      <th>6986</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8.589871</td>\n      <td>1.846000e-04</td>\n      <td>-1.846000e-04</td>\n      <td>132.016100</td>\n      <td>0.015700</td>\n      <td>...</td>\n      <td>-152</td>\n      <td>4.296</td>\n      <td>0.231</td>\n      <td>-0.189</td>\n      <td>1.088</td>\n      <td>0.313</td>\n      <td>-0.228</td>\n      <td>298.74921</td>\n      <td>46.973351</td>\n      <td>14.478</td>\n    </tr>\n    <tr>\n      <th>6987</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.527699</td>\n      <td>1.160000e-07</td>\n      <td>-1.160000e-07</td>\n      <td>131.705093</td>\n      <td>0.000170</td>\n      <td>...</td>\n      <td>-166</td>\n      <td>4.529</td>\n      <td>0.035</td>\n      <td>-0.196</td>\n      <td>0.903</td>\n      <td>0.237</td>\n      <td>-0.079</td>\n      <td>297.18875</td>\n      <td>47.093819</td>\n      <td>14.082</td>\n    </tr>\n    <tr>\n      <th>6989</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.681402</td>\n      <td>2.430000e-06</td>\n      <td>-2.430000e-06</td>\n      <td>132.181750</td>\n      <td>0.002850</td>\n      <td>...</td>\n      <td>-236</td>\n      <td>4.447</td>\n      <td>0.056</td>\n      <td>-0.224</td>\n      <td>1.041</td>\n      <td>0.341</td>\n      <td>-0.114</td>\n      <td>294.16489</td>\n      <td>47.176281</td>\n      <td>15.385</td>\n    </tr>\n    <tr>\n      <th>6990</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.856035</td>\n      <td>6.360000e-05</td>\n      <td>-6.360000e-05</td>\n      <td>135.993300</td>\n      <td>0.010800</td>\n      <td>...</td>\n      <td>-225</td>\n      <td>4.385</td>\n      <td>0.054</td>\n      <td>-0.216</td>\n      <td>1.193</td>\n      <td>0.410</td>\n      <td>-0.137</td>\n      <td>297.00977</td>\n      <td>47.121021</td>\n      <td>14.826</td>\n    </tr>\n  </tbody>\n</table>\n<p>5304 rows Ã— 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "short_df = df.loc[(df['koi_disposition'] == 'CONFIRMED') | (df['koi_disposition'] == 'FALSE POSITIVE')]\n",
    "short_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = df[['koi_period', 'koi_prad', 'koi_fpflag_nt', 'koi_steff', 'koi_slogg', 'koi_srad']]\n",
    "short_selected_features = short_df[['koi_period', 'koi_prad', 'koi_fpflag_nt', 'koi_steff', 'koi_slogg', 'koi_srad']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, df['koi_disposition'], random_state = 10)\n",
    "X_train_short, X_test_short, y_train_short, y_test_short = train_test_split(short_selected_features, short_df['koi_disposition'], random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "X_scaler_short = MinMaxScaler().fit(X_train_short)\n",
    "X_train_scaled_short = X_scaler_short.transform(X_train_short)\n",
    "X_test_scaled_short = X_scaler_short.transform(X_test_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training Data Score: 0.945260347129506\nTesting Data Score: 0.7414187643020596\n"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_model = RandomForestClassifier(n_estimators=200, min_samples_split = 8, n_jobs=-1)\n",
    "forest_model = forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "print(f\"Training Data Score: {forest_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {forest_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training Data Score: 1.0\nTesting Data Score: 0.8838612368024132\n"
    }
   ],
   "source": [
    "#training on shortened model\n",
    "forest_model_short = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    "forest_model_short = forest_model_short.fit(X_train_scaled_short, y_train_short)\n",
    "\n",
    "\n",
    "print(f\"Training Data Score: {forest_model_short.score(X_train_scaled_short, y_train_short)}\")\n",
    "print(f\"Testing Data Score: {forest_model_short.score(X_test_scaled_short, y_test_short)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=200,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "forest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    \"n_estimators\": [50, 200, 500],\n",
    "    \"min_samples_split\": [2, 4, 8],\n",
    "    \"min_weight_fraction_leaf\": [0.0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(forest_model, params, verbose = 2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   19.2s\n[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   50.2s finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv='warn', error_score='raise-deprecating',\n             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n                                              criterion='gini', max_depth=None,\n                                              max_features='auto',\n                                              max_leaf_nodes=None,\n                                              min_impurity_decrease=0.0,\n                                              min_impurity_split=None,\n                                              min_samples_leaf=1,\n                                              min_samples_split=2,\n                                              min_weight_fraction_leaf=0.0,\n                                              n_estimators=200, n_jobs=-1,\n                                              oob_score=False,\n                                              random_state=None, verbose=0,\n                                              warm_start=False),\n             iid='warn', n_jobs=-1,\n             param_grid={'min_samples_split': [2, 4, 8],\n                         'min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3],\n                         'n_estimators': [50, 200, 500]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=2)"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'min_samples_split': 8, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200}\n0.733930955559794\n"
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   15.2s\n[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   38.8s finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv='warn', error_score='raise-deprecating',\n             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n                                              criterion='gini', max_depth=None,\n                                              max_features='auto',\n                                              max_leaf_nodes=None,\n                                              min_impurity_decrease=0.0,\n                                              min_impurity_split=None,\n                                              min_samples_leaf=1,\n                                              min_samples_split=8,\n                                              min_weight_fraction_leaf=0.0,\n                                              n_estimators=200, n_jobs=-1,\n                                              oob_score=False,\n                                              random_state=None, verbose=0,\n                                              warm_start=False),\n             iid='warn', n_jobs=-1,\n             param_grid={'min_samples_split': [2, 4, 8],\n                         'min_weight_fraction_leaf': [0.0, 0.1, 0.2, 0.3],\n                         'n_estimators': [50, 200, 500]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=2)"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "#gridsearch for shortened df\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params_short = {\n",
    "    \"n_estimators\": [50, 200, 500],\n",
    "    \"min_samples_split\": [2, 4, 8],\n",
    "    \"min_weight_fraction_leaf\": [0.0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "grid_short = GridSearchCV(forest_model, params_short, verbose = 2, n_jobs = -1)\n",
    "grid_short.fit(X_train_scaled_short, y_train_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 500}\n0.8888888888888888\n"
    }
   ],
   "source": [
    "print(grid_short.best_params_)\n",
    "print(grid_short.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['forest_model.sav']"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "\n",
    "forest_model = RandomForestClassifier(min_samples_split=8, min_weight_fraction_leaf=0, n_estimators=200)\n",
    "forest_model = forest_model.fit(X_train, y_train)\n",
    "\n",
    "filename = 'forest_model.sav'\n",
    "joblib.dump(forest_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python36764bitpythondatacondac93f1d0824da4ea88fdc3c2e1b2950d1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}